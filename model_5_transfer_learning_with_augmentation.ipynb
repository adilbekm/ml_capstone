{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: transfer learning with image augmentation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Needs editing]\n",
    "\n",
    "In this notebook, I implement transfer learning using the ResNet50 pre-trained network.\n",
    "\n",
    "Predictions made using this model scored 0.277 by Kaggle, slightly better than the 2nd model's score of 0.276 but worse than the 1st model's score of 0.283 (submitted to Kaggle on Jan 20, 2019).\n",
    "\n",
    "Hardware used: CPU: i5 2.10GHz x 6, GPU: none: RAM: 16Gb + 32Gb virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, AveragePooling2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image         Id\n",
      "0  0000e88ab.jpg  w_f48451c\n",
      "1  0001f9222.jpg  w_c3d896a\n",
      "2  00029d126.jpg  w_20df2c5\n",
      "3  00050a15a.jpg  new_whale\n",
      "4  0005c1ef8.jpg  new_whale\n",
      "25361\n"
     ]
    }
   ],
   "source": [
    "# load train files and labels into dataframe\n",
    "traindf_all = pd.read_csv('train.csv')\n",
    "print(traindf_all.head())\n",
    "print(len(traindf_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15697\n"
     ]
    }
   ],
   "source": [
    "# remove unlabeled images\n",
    "traindf = traindf_all.drop(traindf_all[traindf_all.Id == 'new_whale'].index.tolist())\n",
    "traindf.reset_index(drop=True, inplace=True)\n",
    "del traindf_all\n",
    "print(len(traindf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Count\n",
      "0  w_f48451c     14\n",
      "1  w_c3d896a      4\n",
      "2  w_20df2c5      4\n",
      "5004\n"
     ]
    }
   ],
   "source": [
    "# create dataframe with distinct ids and count of images per id\n",
    "ids = pd.DataFrame(traindf['Id'].unique(), columns=['Id'])\n",
    "ids['Count'] = 0\n",
    "for r in ids.itertuples():\n",
    "    id = r.Id\n",
    "    cnt = len(traindf[traindf['Id'] == id])\n",
    "    ind = ids[ids['Id'] == id].index.values[0]\n",
    "    ids.loc[ind, 'Count'] = cnt\n",
    "print(ids.head(3))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image dimensions and color mode for all training images\n",
    "traindf['Width'] = 0\n",
    "traindf['Height'] = 0\n",
    "traindf['Mode'] = ''\n",
    "i = 0\n",
    "for r in traindf.itertuples(): \n",
    "    img_name = r.Image \n",
    "    img_path = 'train/' + img_name\n",
    "    img = Image.open(img_path) \n",
    "    width, height = img.size\n",
    "    mode = img.mode\n",
    "    traindf.loc[i, ['Width', 'Height', 'Mode']] = width, height, mode\n",
    "    i += 1\n",
    "print(traindf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Transfer Learning ###\n",
    "\n",
    "In the following cells, I use the bottleneck features for the ResNet50 pretrained network that I obtained earlier. \n",
    "\n",
    "See section **\"Obtaining Bottleneck Features\"** at the end of the notebook for code and other details.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved bottleneck features and labels\n",
    "bnfeatures_train = np.load('tensors/model_5/bnfeatures_train.npy')\n",
    "# we already have the right labels, from Model 2\n",
    "tensors_train_labels = np.load('tensors/model_2/tensors_train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5004)              1286028   \n",
      "=================================================================\n",
      "Total params: 26,976,396\n",
      "Trainable params: 26,976,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model to go as last layer to pretrained model\n",
    "INPUT_SHAPE = bnfeatures_train.shape[1:]\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=INPUT_SHAPE))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5004, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22518 samples, validate on 2502 samples\n",
      "Epoch 1/10\n",
      "22518/22518 [==============================] - 304s 14ms/step - loss: 8.5542 - acc: 4.4409e-05 - val_loss: 8.9614 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.96144, saving model to saved_models/weights.model_5.h5\n",
      "Epoch 2/10\n",
      "22518/22518 [==============================] - 301s 13ms/step - loss: 8.4994 - acc: 4.4409e-05 - val_loss: 9.2983 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 8.96144\n",
      "Epoch 3/10\n",
      "22518/22518 [==============================] - 297s 13ms/step - loss: 8.4902 - acc: 0.0000e+00 - val_loss: 9.5896 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 8.96144\n",
      "Epoch 4/10\n",
      "22518/22518 [==============================] - 296s 13ms/step - loss: 8.4850 - acc: 8.8818e-05 - val_loss: 9.8603 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 8.96144\n",
      "Epoch 5/10\n",
      "22518/22518 [==============================] - 298s 13ms/step - loss: 8.4815 - acc: 0.0000e+00 - val_loss: 10.1210 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 8.96144\n",
      "Epoch 6/10\n",
      "22518/22518 [==============================] - 297s 13ms/step - loss: 8.4790 - acc: 8.8818e-05 - val_loss: 10.3766 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 8.96144\n",
      "Epoch 7/10\n",
      "22518/22518 [==============================] - 296s 13ms/step - loss: 8.4771 - acc: 8.8818e-05 - val_loss: 10.6285 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 8.96144\n",
      "Epoch 8/10\n",
      "22518/22518 [==============================] - 298s 13ms/step - loss: 8.4756 - acc: 0.0000e+00 - val_loss: 10.8769 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 8.96144\n",
      "Epoch 9/10\n",
      "22518/22518 [==============================] - 297s 13ms/step - loss: 8.4744 - acc: 0.0000e+00 - val_loss: 11.1207 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 8.96144\n",
      "Epoch 10/10\n",
      "22518/22518 [==============================] - 296s 13ms/step - loss: 8.4734 - acc: 8.8818e-05 - val_loss: 11.3583 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 8.96144\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.model_5.h5', verbose=1, save_best_only=True)\n",
    "history = model.fit(\n",
    "        x=bnfeatures_train,\n",
    "        y=tensors_train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpointer],\n",
    "        validation_split=0.1,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights('saved_models/weights.model_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved bottleneck features of testing set\n",
    "# note, that we already created the right data in Model 3\n",
    "bnfeatures_test = np.load('tensors/model_3/bnfeatures_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960/7960 [==============================] - 5s 664us/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(bnfeatures_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(ids.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image\n",
      "0  21253f840.jpg\n",
      "1  769f8d32b.jpg\n",
      "2  a69dc856e.jpg\n",
      "7960\n"
     ]
    }
   ],
   "source": [
    "# load test files into dataframe\n",
    "filelist = os.listdir('test')\n",
    "testdf = pd.DataFrame(filelist, columns=['Image'])\n",
    "print(testdf.head(3))\n",
    "print(len(testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  21253f840.jpg  new_whale w_dfbf100 w_b708e98 w_dced3f2 w_d9d1e17\n",
      "1  769f8d32b.jpg  new_whale w_dfbf100 w_b708e98 w_dced3f2 w_d9d1e17\n",
      "2  a69dc856e.jpg  new_whale w_dfbf100 w_b708e98 w_dced3f2 w_d9d1e17\n",
      "3  79bee536e.jpg  new_whale w_dfbf100 w_b708e98 w_dced3f2 w_d9d1e17\n",
      "4  7eb9a6f1b.jpg  new_whale w_dfbf100 w_b708e98 w_dced3f2 w_d9d1e17\n"
     ]
    }
   ],
   "source": [
    "# get 5 best predictions per image and decode to whale ids\n",
    "# insert \"new_whale\" where prediction probability drops below 10% \n",
    "testdf['Id'] = ''\n",
    "for i, pred in enumerate(predictions):\n",
    "    inx = np.argsort(pred)[-5:][::-1].tolist()\n",
    "    preds = labels[inx].tolist()\n",
    "    probs = pred[inx]\n",
    "    try:\n",
    "        # get index of first prediction with prob less than 10%\n",
    "        j = (probs < 0.1).tolist().index(True)\n",
    "        # enter \"new_whale\" in that index, and shift any remaining preds to right\n",
    "        for ii in range(4, (j-1), -1):\n",
    "            if ii==j:\n",
    "                preds[ii] = 'new_whale'\n",
    "            else:\n",
    "                preds[ii] = preds[ii-1]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    testdf.loc[i,'Id'] = ' '.join(preds)\n",
    "print(testdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file and submit to Kaggle\n",
    "testdf.to_csv('submissions/submit_0121_02.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scored 0.276, worse than my 1st model's score of 0.281.\n",
    "\n",
    "This model is making about the same prediction for all images. The Ids that it is predicting are those that have the most number of images in the training set. So, Id \"w_23a388d\" has 73 images, \"w_9b5109b\" has 65, itc. The model is clearly biased towards the wales it has seen the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Obtaining Bottleneck Features ###\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model, with last layer removed\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "model_resnet50 = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert images to tensors\n",
    "# (same as created in Model 1)\n",
    "def imgs_to_tensors(df, path, size=(100, 100)):\n",
    "    '''\n",
    "    df: dataframe listing image file names in column \"Image\"\n",
    "    path: directory where image files are located (don't include /)\n",
    "    size: target height and width to resize images to\n",
    "    '''\n",
    "    HEIGHT, WIDTH = size\n",
    "    LEN=df.shape[0]   \n",
    "    tensors = np.zeros((LEN, HEIGHT, WIDTH, 3))\n",
    "    i = 0\n",
    "    for im_name in df.Image:\n",
    "        if (i%1000==0):\n",
    "            print('Processing image {}: {}'.format(i, im_name))\n",
    "        im_path = path + '/' + im_name\n",
    "        # load image to PIL format\n",
    "        im = image.load_img(path=im_path, \n",
    "                            grayscale=False, \n",
    "                            color_mode='rgb', \n",
    "                            target_size=(HEIGHT, WIDTH), \n",
    "                            interpolation='nearest')\n",
    "        # convert to numpy array/tensor with shape (HEIGHT, WIDTH, 3)\n",
    "        x = image.img_to_array(im)\n",
    "        x = preprocess_input(x) # important line! I am not sure why\n",
    "        tensors[i] = x\n",
    "        i += 1   \n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe for balanced dataset created in Model 2\n",
    "# (25,020 images total or 5 images per label, using augmented images where there are fewer than 5 images)\n",
    "subset = pd.read_csv('subset.csv')\n",
    "print(subset.head())\n",
    "print(len(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training tensors and save on disk\n",
    "# (ResNet50 requires input images to be in shape 224x224)\n",
    "# (divide by 255 to normalize pixel values)\n",
    "tensors_train = imgs_to_tensors(df=subset, path='augmented/train', size=(224, 224))/255\n",
    "np.save('tensors/model_5/tensors_train', tensors_train)\n",
    "print(tensors_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bottleneck features from training tensors, and save on disk\n",
    "bnfeatures_train = model_resnet50.predict(tensors_train, verbose=1)\n",
    "np.save('tensors/model_5/bnfeatures_train', bnfeatures_train)\n",
    "print(bnfeatures_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test files into dataframe\n",
    "filelist = os.listdir('test')\n",
    "testdf = pd.DataFrame(filelist, columns=['Image'])\n",
    "print(testdf.head(3))\n",
    "print(len(testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing tensors, and save on disk\n",
    "# (ResNet50 requires input images to be in shape 224x224)\n",
    "# (divide by 255 to normalize pixel values)\n",
    "tensors_test = imgs_to_tensors(df=testdf, path='test', size=(224, 224))/255\n",
    "np.save('tensors/model_3/tensors_test', tensors_test)\n",
    "print(tensors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bottleneck features from testing tensors, and save on disk\n",
    "bnfeatures_test = model_resnet50.predict(tensors_test, verbose=1)\n",
    "np.save('tensors/model_3/bnfeatures_test', bnfeatures_test)\n",
    "print(bnfeatures_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
