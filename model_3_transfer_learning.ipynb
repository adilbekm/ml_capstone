{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: transfer learning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I implement transfer learning using the ResNet50 pre-trained network.\n",
    "\n",
    "Predictions made using this model scored 0.277 by Kaggle, slightly better than the 2nd model's score of 0.276 but worse than the 1st model's score of 0.283 (submitted to Kaggle on Jan 20, 2019).\n",
    "\n",
    "Hardware used: CPU: i5 2.10GHz x 6, GPU: none: RAM: 16Gb + 32Gb virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, AveragePooling2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image         Id\n",
      "0  0000e88ab.jpg  w_f48451c\n",
      "1  0001f9222.jpg  w_c3d896a\n",
      "2  00029d126.jpg  w_20df2c5\n",
      "3  00050a15a.jpg  new_whale\n",
      "4  0005c1ef8.jpg  new_whale\n",
      "25361\n"
     ]
    }
   ],
   "source": [
    "# load train files and labels into dataframe\n",
    "traindf_all = pd.read_csv('train.csv')\n",
    "print(traindf_all.head())\n",
    "print(len(traindf_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15697\n"
     ]
    }
   ],
   "source": [
    "# remove unlabeled images\n",
    "traindf = traindf_all.drop(traindf_all[traindf_all.Id == 'new_whale'].index.tolist())\n",
    "traindf.reset_index(drop=True, inplace=True)\n",
    "del traindf_all\n",
    "print(len(traindf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id  Count\n",
      "0  w_f48451c     14\n",
      "1  w_c3d896a      4\n",
      "2  w_20df2c5      4\n",
      "5004\n"
     ]
    }
   ],
   "source": [
    "# create dataframe with distinct ids and count of images per id\n",
    "ids = pd.DataFrame(traindf['Id'].unique(), columns=['Id'])\n",
    "ids['Count'] = 0\n",
    "for r in ids.itertuples():\n",
    "    id = r.Id\n",
    "    cnt = len(traindf[traindf['Id'] == id])\n",
    "    ind = ids[ids['Id'] == id].index.values[0]\n",
    "    ids.loc[ind, 'Count'] = cnt\n",
    "print(ids.head(3))\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image dimensions and color mode for all training images\n",
    "traindf['Width'] = 0\n",
    "traindf['Height'] = 0\n",
    "traindf['Mode'] = ''\n",
    "i = 0\n",
    "for r in traindf.itertuples(): \n",
    "    img_name = r.Image \n",
    "    img_path = 'train/' + img_name\n",
    "    img = Image.open(img_path) \n",
    "    width, height = img.size\n",
    "    mode = img.mode\n",
    "    traindf.loc[i, ['Width', 'Height', 'Mode']] = width, height, mode\n",
    "    i += 1\n",
    "print(traindf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Transfer Learning ###\n",
    "\n",
    "In the following cells, I use the bottleneck features for the ResNet50 pretrained network that I obtained earlier. \n",
    "\n",
    "See section **\"Obtaining Bottleneck Features\"** at the end of the notebook for code and other details.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved bottleneck features and labels\n",
    "bnfeatures_train = np.load('tensors/model_3/bnfeatures_train.npy')\n",
    "tensors_train_labels = np.load('tensors/model_1/tensors_train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5004)              1286028   \n",
      "=================================================================\n",
      "Total params: 26,976,396\n",
      "Trainable params: 26,976,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model to go as last layer to pretrained model\n",
    "INPUT_SHAPE = bnfeatures_train.shape[1:]\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=INPUT_SHAPE))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5004, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14127 samples, validate on 1570 samples\n",
      "Epoch 1/10\n",
      "14127/14127 [==============================] - 199s 14ms/step - loss: 8.4871 - acc: 0.0040 - val_loss: 8.4636 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.46365, saving model to saved_models/weights.model_3.h5\n",
      "Epoch 2/10\n",
      "14127/14127 [==============================] - 193s 14ms/step - loss: 8.3539 - acc: 0.0048 - val_loss: 8.4913 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 8.46365\n",
      "Epoch 3/10\n",
      "14127/14127 [==============================] - 193s 14ms/step - loss: 8.3041 - acc: 0.0048 - val_loss: 8.5163 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 8.46365\n",
      "Epoch 4/10\n",
      "14127/14127 [==============================] - 194s 14ms/step - loss: 8.2626 - acc: 0.0048 - val_loss: 8.5403 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 8.46365\n",
      "Epoch 5/10\n",
      "14127/14127 [==============================] - 195s 14ms/step - loss: 8.2264 - acc: 0.0048 - val_loss: 8.5646 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 8.46365\n",
      "Epoch 6/10\n",
      "14127/14127 [==============================] - 195s 14ms/step - loss: 8.1944 - acc: 0.0048 - val_loss: 8.5900 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 8.46365\n",
      "Epoch 7/10\n",
      "14127/14127 [==============================] - 195s 14ms/step - loss: 8.1659 - acc: 0.0048 - val_loss: 8.6175 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 8.46365\n",
      "Epoch 8/10\n",
      "14127/14127 [==============================] - 196s 14ms/step - loss: 8.1408 - acc: 0.0048 - val_loss: 8.6469 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 8.46365\n",
      "Epoch 9/10\n",
      "14127/14127 [==============================] - 194s 14ms/step - loss: 8.1187 - acc: 0.0048 - val_loss: 8.6783 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 8.46365\n",
      "Epoch 10/10\n",
      "14127/14127 [==============================] - 193s 14ms/step - loss: 8.0993 - acc: 0.0048 - val_loss: 8.7118 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 8.46365\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.model_3.h5', verbose=1, save_best_only=True)\n",
    "history = model.fit(\n",
    "        x=bnfeatures_train,\n",
    "        y=tensors_train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpointer],\n",
    "        validation_split=0.1,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights('saved_models/weights.model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved bottleneck features of testing set\n",
    "bnfeatures_test = np.load('tensors/model_3/bnfeatures_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960/7960 [==============================] - 6s 766us/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(bnfeatures_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(ids.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  21253f840.jpg  new_whale w_23a388d w_9b5109b w_0369a5c w_3de579a\n",
      "1  769f8d32b.jpg  new_whale w_23a388d w_9b5109b w_0369a5c w_3de579a\n",
      "2  a69dc856e.jpg  new_whale w_23a388d w_9b5109b w_0369a5c w_3de579a\n",
      "3  79bee536e.jpg  new_whale w_23a388d w_9b5109b w_0369a5c w_3de579a\n",
      "4  7eb9a6f1b.jpg  new_whale w_23a388d w_9b5109b w_0369a5c w_3de579a\n"
     ]
    }
   ],
   "source": [
    "# get 5 best predictions per image and decode to whale ids\n",
    "# insert \"new_whale\" where prediction probability drops below 10% \n",
    "testdf['Id'] = ''\n",
    "for i, pred in enumerate(predictions):\n",
    "    inx = np.argsort(pred)[-5:][::-1].tolist()\n",
    "    preds = labels[inx].tolist()\n",
    "    probs = pred[inx]\n",
    "    try:\n",
    "        # get index of first prediction with prob less than 10%\n",
    "        j = (probs < 0.1).tolist().index(True)\n",
    "        # enter \"new_whale\" in that index, and shift any remaining preds to right\n",
    "        for ii in range(4, (j-1), -1):\n",
    "            if ii==j:\n",
    "                preds[ii] = 'new_whale'\n",
    "            else:\n",
    "                preds[ii] = preds[ii-1]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    testdf.loc[i,'Id'] = ' '.join(preds)\n",
    "print(testdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file and submit to Kaggle\n",
    "testdf.to_csv('submissions/submit_0120_01.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scored 0.277, worse than my 1st model's score of 0.281.\n",
    "\n",
    "This model is making about the same prediction for all images. The Ids that it is predicting are those that have the most number of images in the training set. So, Id \"w_23a388d\" has 73 images, \"w_9b5109b\" has 65, itc. The model is clearly biased towards the wales it has seen the most. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Obtaining Bottleneck Features ###\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model, with last layer removed\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "model_resnet50 = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert images to tensors\n",
    "# (same as created in Model 1)\n",
    "def imgs_to_tensors(df, path, size=(100, 100)):\n",
    "    '''\n",
    "    df: dataframe listing image file names in column \"Image\"\n",
    "    path: directory where image files are located (don't include /)\n",
    "    size: target height and width to resize images to\n",
    "    '''\n",
    "    HEIGHT, WIDTH = size\n",
    "    LEN=df.shape[0]   \n",
    "    tensors = np.zeros((LEN, HEIGHT, WIDTH, 3))\n",
    "    i = 0\n",
    "    for im_name in df.Image:\n",
    "        if (i%1000==0):\n",
    "            print('Processing image {}: {}'.format(i, im_name))\n",
    "        im_path = path + '/' + im_name\n",
    "        # load image to PIL format\n",
    "        im = image.load_img(path=im_path, \n",
    "                            grayscale=False, \n",
    "                            color_mode='rgb', \n",
    "                            target_size=(HEIGHT, WIDTH), \n",
    "                            interpolation='nearest')\n",
    "        # convert to numpy array/tensor with shape (HEIGHT, WIDTH, 3)\n",
    "        x = image.img_to_array(im)\n",
    "        x = preprocess_input(x) # important line! I am not sure why\n",
    "        tensors[i] = x\n",
    "        i += 1   \n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0: 0000e88ab.jpg\n",
      "Processing image 1000: 10b694367.jpg\n",
      "Processing image 2000: 21e28ae02.jpg\n",
      "Processing image 3000: 32533a7fb.jpg\n",
      "Processing image 4000: 42f134dea.jpg\n",
      "Processing image 5000: 5297b6c40.jpg\n",
      "Processing image 6000: 6311688b7.jpg\n",
      "Processing image 7000: 7390cbfab.jpg\n",
      "Processing image 8000: 83336c385.jpg\n",
      "Processing image 9000: 92f450203.jpg\n",
      "Processing image 10000: a39babc55.jpg\n",
      "Processing image 11000: b36da6f7c.jpg\n",
      "Processing image 12000: c4160ee65.jpg\n",
      "Processing image 13000: d3b15e280.jpg\n",
      "Processing image 14000: e3fe27a84.jpg\n",
      "Processing image 15000: f3f3f8b92.jpg\n",
      "(15697, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# create training tensors and save on disk\n",
    "# (ResNet50 requires input images to be in shape 224x224)\n",
    "# (divide by 255 to normalize pixel values)\n",
    "tensors_train = imgs_to_tensors(df=traindf, path='train', size=(224, 224))/255\n",
    "np.save('tensors/model_3/tensors_train', tensors_train)\n",
    "print(tensors_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15697/15697 [==============================] - 1541s 98ms/step\n",
      "(15697, 7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "# create bottleneck features from training tensors, and save on disk\n",
    "bnfeatures_train = model_resnet50.predict(tensors_train, verbose=1)\n",
    "np.save('tensors/model_3/bnfeatures_train', bnfeatures_train)\n",
    "print(bnfeatures_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image\n",
      "0  21253f840.jpg\n",
      "1  769f8d32b.jpg\n",
      "2  a69dc856e.jpg\n",
      "7960\n"
     ]
    }
   ],
   "source": [
    "# load test files into dataframe\n",
    "filelist = os.listdir('test')\n",
    "testdf = pd.DataFrame(filelist, columns=['Image'])\n",
    "print(testdf.head(3))\n",
    "print(len(testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0: 21253f840.jpg\n",
      "Processing image 1000: b14876130.jpg\n",
      "Processing image 2000: 8d8c7a728.jpg\n",
      "Processing image 3000: ca3921cc1.jpg\n",
      "Processing image 4000: e23615e20.jpg\n",
      "Processing image 5000: 0e5538c86.jpg\n",
      "Processing image 6000: 3234bf468.jpg\n",
      "Processing image 7000: 465b5b1ab.jpg\n",
      "(7960, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# create testing tensors, and save on disk\n",
    "# (ResNet50 requires input images to be in shape 224x224)\n",
    "# (divide by 255 to normalize pixel values)\n",
    "tensors_test = imgs_to_tensors(df=testdf, path='test', size=(224, 224))/255\n",
    "np.save('tensors/model_3/tensors_test', tensors_test)\n",
    "print(tensors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960/7960 [==============================] - 740s 93ms/step\n",
      "(7960, 7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "# create bottleneck features from testing tensors, and save on disk\n",
    "bnfeatures_test = model_resnet50.predict(tensors_test, verbose=1)\n",
    "np.save('tensors/model_3/bnfeatures_test', bnfeatures_test)\n",
    "print(bnfeatures_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
